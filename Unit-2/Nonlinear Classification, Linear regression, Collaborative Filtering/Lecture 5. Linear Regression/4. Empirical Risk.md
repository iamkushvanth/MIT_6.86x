# **Compute Hinge Loss**

The empirical risk **\( R_n(\theta) \)** is defined as

**\[ R_n(\theta) = \frac{1}{n} \sum_{t=1}^n \text{Loss}(y^t, \theta \cdot x^t) \]**

where **\( (x^t, y^t) \) is the \( t \)-th** training example (and there are **\( n \)** in total), and Loss is some loss function, such as hinge loss.

Recall from a previous lecture that the definition of hinge loss:

**\[ \text{Loss}_\text{hinge}(z) = \begin{cases} 0 & \text{if } z \geq 1 \\ 1 - z & \text{otherwise} \end{cases} \]**

In this problem, we calculate the empirical risk with hinge loss when given specific **\( \theta \) and \( \{ (x^t, y^t) \}_{t=1}^n \)**.

Assume we have 4 training examples (i.e. **\( n = 4 \)), where \( x^t \in \mathbb{R}^2 \) and \( y^t \)** is a scalar. The training examples **\( \{ (x^t, y^t) \}_{t=1,2,3,4} \)** are given as follows:


**
(x^1, y^1) & :  [1, 0, 1]^T  |  2  
(x^2, y^2) & :  [1, 1, 1]^T  |  2.7  
(x^3, y^3) & :  [1, 1, -1]^T |  -0.7  
(x^4, y^4) & :  [-1, 1, 1]^T |  2 
**


Also, we have **\( \theta = [0, 1, 2]^T \)**.

Compute the value of

**\[ R_n(\theta) = \frac{1}{4} \sum_{t=1}^4 \text{Loss}(y^t - \theta \cdot x^t) \]**

**Ans:**

# **Compute Squared Error Loss**

Now, we will calculate the empirical risk with the squared error loss. Remember that the squared error loss is given by

**\[ \text{Loss}(z) = \frac{z^2}{2} \]**

The 4 training examples are as in the previous problem:

**
(x^1, y^1) & :  [1, 0, 1]^T  |  2  
(x^2, y^2) & :  [1, 1, 1]^T  |  2.7  
(x^3, y^3) & :  [1, 1, -1]^T |  -0.7  
(x^4, y^4) & :  [-1, 1, 1]^T |  2 
**

As in the problem above, we have **\( \theta = [0, 1, 2]^T \)**.

Compute the value of

**\[ R_n(\theta) = \frac{1}{4} \sum_{t=1}^4 \text{Loss}(y^t - \theta \cdot x^t) \]**

**Ans:**

# **Geometrically Identifying Error**

What type of error does the figure below depict? The blue dots are the training examples, and the red line is the predictor **\( \hat{f}(x) \)**

[ ] Structural error
[ ] Estimation error

**Ans:**

# **Empirical Risk and Model Performance**

If we are given a large amount of training data and successfully obtain 0 empirical risk, is the model we learned guaranteed to perform well on the test data? (Assume training and test data are drawn from the same distribution.)

[ ] Yes.
[ ] No.

**Ans:**






